{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Video prediction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "thvpwusmbZtL"
      },
      "source": [
        "# Video Face Manipulation Detection Through Ensemble of CNNs\n",
        "Image and Sound Processing Lab - Politecnico di Milano\n",
        "- Nicol√≤ Bonettini\n",
        "- Edoardo Daniele Cannas\n",
        "- Sara Mandelli\n",
        "- Luca Bondi\n",
        "- Paolo Bestagini\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M66N8SyQf7I5"
      },
      "source": [
        "!git clone https://github.com/polimi-ispl/icpr2020dfdc.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNXNZy5GhXV7"
      },
      "source": [
        "cd icpr2020dfdc/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmtzAwHgibLh"
      },
      "source": [
        "! pip install albumentations==0.4.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxNokWzATCdM"
      },
      "source": [
        "! pip install --upgrade efficientnet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCZNzYUCbZtQ"
      },
      "source": [
        "import torch\n",
        "from torch.utils.model_zoo import load_url\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import expit\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
        "from architectures import fornet, weights\n",
        "from isplutils import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRTtonGtbZtR"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-HgxLJWbZtR"
      },
      "source": [
        "\"\"\"\n",
        "Choose an architecture between\n",
        "- EfficientNetB4\n",
        "- EfficientNetB4ST\n",
        "- EfficientNetAutoAttB4\n",
        "- EfficientNetAutoAttB4ST\n",
        "- Xception\n",
        "\"\"\"\n",
        "net_model = 'EfficientNetAutoAttB4'\n",
        "\n",
        "\"\"\"\n",
        "Choose a training dataset between\n",
        "- DFDC\n",
        "- FFPP\n",
        "\"\"\"\n",
        "train_db = 'DFDC'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB0oCWQzbZtR"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "face_policy = 'scale'\n",
        "face_size = 224\n",
        "frames_per_video = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk_O6oR0bZtS"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KB-03EbZtS"
      },
      "source": [
        "model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n",
        "net = getattr(fornet,net_model)().eval().to(device)\n",
        "net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNfa2HU5bZtT"
      },
      "source": [
        "transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unM4gOVRbZtT"
      },
      "source": [
        "facedet = BlazeFace().to(device)\n",
        "facedet.load_weights(\"blazeface/blazeface.pth\")\n",
        "facedet.load_anchors(\"blazeface/anchors.npy\")\n",
        "videoreader = VideoReader(verbose=False)\n",
        "video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
        "face_extractor = FaceExtractor(video_read_fn=video_read_fn,facedet=facedet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHPB1HzAbZtT"
      },
      "source": [
        "## Detect faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf5WSY7mlmcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlHOBVejbZtT"
      },
      "source": [
        "vid_real_faces = face_extractor.process_video('/content/gdrive/My Drive/DeepFake Detection/dw_noeyes.mp4')\n",
        "vid_fake_faces = face_extractor.process_video('/content/gdrive/My Drive/DeepFake Detection/putin_fake_noeyes.mp4')\n",
        "\n",
        "#vid_real_faces = face_extractor.process_video('notebook/samples/lynaeydofd.mp4')\n",
        "#vid_fake_faces = face_extractor.process_video('notebook/samples/mqzvfufzoq.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPcwtR5CbZtU"
      },
      "source": [
        "im_real_face = vid_real_faces[0]['faces'][0]\n",
        "im_fake_face = vid_fake_faces[0]['faces'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHk4JJCbZtU"
      },
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
        "\n",
        "ax[0].imshow(im_real_face)\n",
        "ax[0].set_title('REAL')\n",
        "\n",
        "ax[1].imshow(im_fake_face)\n",
        "ax[1].set_title('FAKE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RkHekQ4bZtU"
      },
      "source": [
        "## Predict scores for each frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJD6gc0xbZtU"
      },
      "source": [
        "# For each frame, we consider the face with the highest confidence score found by BlazeFace (= frame['faces'][0])\n",
        "faces_real_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_real_faces if len(frame['faces'])] )\n",
        "faces_fake_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_fake_faces if len(frame['faces'])] )\n",
        "\n",
        "with torch.no_grad():\n",
        "    faces_real_pred = net(faces_real_t.to(device)).cpu().numpy().flatten()\n",
        "    faces_fake_pred = net(faces_fake_t.to(device)).cpu().numpy().flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dc0B5VzbZtU"
      },
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(12,4))\n",
        "\n",
        "ax[0].stem([f['frame_idx'] for f in vid_real_faces if len(f['faces'])],expit(faces_real_pred),use_line_collection=True)\n",
        "ax[0].set_title('REAL')\n",
        "ax[0].set_xlabel('Frame')\n",
        "ax[0].set_ylabel('Score')\n",
        "ax[0].set_ylim([0,1])\n",
        "ax[0].grid(True)\n",
        "\n",
        "ax[1].stem([f['frame_idx'] for f in vid_fake_faces if len(f['faces'])],expit(faces_fake_pred),use_line_collection=True)\n",
        "ax[1].set_title('FAKE')\n",
        "ax[1].set_xlabel('Frame')\n",
        "ax[1].set_ylabel('Score')\n",
        "ax[1].set_ylim([0,1])\n",
        "ax[1].set_yticks([0,1],['REAL','FAKE']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUhxIt1NbZtV"
      },
      "source": [
        "\"\"\"\n",
        "Print average scores.\n",
        "An average score close to 0 predicts REAL. An average score close to 1 predicts FAKE.\n",
        "\"\"\"\n",
        "print('Average score for REAL video: {:.4f}'.format(expit(faces_real_pred.mean())))\n",
        "print('Average score for FAKE face: {:.4f}'.format(expit(faces_fake_pred.mean())))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}